{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Олег Дмитриев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксплоратоный анализ данных представлен в блокноте с названием data_exploration.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор модели и метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Факторы определяющие выбор модели и метрики для оценки ее качества:\n",
    "\n",
    "- Задача, поставленная в задании, требует от модели ответа на вопрос, а не выбора среди вариантов ответа. \n",
    "\n",
    "- Нужно научиться отвечать на вопрос основе предоставленных доĸументов. Вход: Вопрос + Доĸумент. Это задача не так сложна. Можно использовать генеративные модели, однако они требуют большого количества вычислительных ресурсов как на стадии обучения, так и на стадии инференса. Я остановился на модели которая находит ответ в контексте, а не генерирует его сама.\n",
    "\n",
    "- Также нужно научиться отвечать на вопрос без предоставленного документа. Этот таск по сложнее. Предполагается, что это может быть вопрос по какому-то из документов датасета. В этом случае будем использовать библиотеку [langchain](https://www.langchain.com/) и [Annoy](https://python.langchain.com/docs/integrations/vectorstores/annoy) для индексации документов вытаскивания подходящих. Будем индексировать тренировочный датасет.\n",
    "\n",
    "- Тк ответы не являются цитированием контекста (как в SQuAD), поэтому не подойдут метрики, основанные на пересечении слов в ответе и контексте. Придется находить косинусное расстояние (1 - cosine similarity) между векторами ответа данного моделью и векторами ответов из датасета. Модель дала правильный ответ, если косинусное расстояние между ответом модели и ЛЮБЫМ из  правильных ответов из датасета наименьшее. Тк модель ищет ответ на вопрос в контексте, то учесть несколько вариантов ответа на вопрос не получится. Поэтому я буду использовать только первый вариант ответа на вопрос из датасета. По определению это метрика accuracy.\n",
    "\n",
    "- Также предлагается использовать метрику MRR (Mean Reciprocal Rank). Мы ранжируем косинусные расстояния между ответом модели и ответами из датасета. Reciprocal Rank - это обратное ранговое значение первого правильного ответа. Усредним эти значения по всем вопросам. Получим MRR.\n",
    "\n",
    "\n",
    "Ниже можно ознакомиться с кодом, который реализует описанную выше логику. Готовый продукт представлен в streamlit приложении. Запустить его можно командой:\n",
    "\n",
    "```shell\n",
    "streamlit run streamlit_app.py\n",
    "```\n",
    "\n",
    "Для запуска потребуется создать виртуальное окружение и установить зависимости:\n",
    "\n",
    "```shell\n",
    "conda create --name biocad-ml-env python=3.11\n",
    "conda activate biocad-ml-env\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Альтернативой является использование [Dockerfile](Dockerfile)\n",
    "\n",
    "* `docker build -t ml-biocad-image .`\n",
    "\n",
    "* Запускаем контейнер, прикрепляем к нему папку с репозиторием и запускаем streamlit приложение\n",
    "```shell\n",
    "docker run -it --name ml-biocad-cont -v ПУТЬ_ДО_ПАПКИ_С_КОДОМ:/ml ml-biocad-image\n",
    "cd /ml\n",
    "streamlit run streamlit_app.py --server.port=8501 --server.address=0.0.0.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/langley/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-19 15:04:11.451862: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-19 15:04:11.473014: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 15:04:11.536766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 15:04:11.536819: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 15:04:11.536906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 15:04:11.557712: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 15:04:12.589845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import numpy as np \n",
    "from tqdm import tqdm   \n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ' Но люди не могут существовать без природы, поэтому в парке стояли железобетонные скамейки — деревянные моментально ломали.  В парке бегали ребятишки, водилась шпана, которая развлекалась игрой в карты, пьянкой, драками, «иногда насмерть».  «Имали они тут и девок...»  Верховодил шпаной Артемка-мыло, с вспененной белой головой.  Людочка сколько ни пыталась усмирить лохмотья на буйной голове Артемки, ничего у неё не получалось.  Его «кудри, издали напоминавшие мыльную пену, изблизя оказались что липкие рожки из вокзальной столовой — сварили их, бросили комком в пустую тарелку, так они, слипшиеся, неподъёмно и лежали.  Да и не ради причёски приходил парень к Людочке.  Как только её руки становились занятыми ножницами и расчёской, Артемка начинал хватать её за разные места.  Людочка сначала увёртывалась от хватких рук Артемки, а когда не помогло, стукнула его машинкой по голове и пробила до крови, пришлось лить йод на голову «ухажористого человека».  Артемка заулюлюкал и со свистом стал ловить воздух.  С тех пор «домогания свои хулиганские прекратил», более того, шпане повелел Людочку не трогать.',\n",
       " 'question': 'Как развлекались в парке ребята?',\n",
       " 'answers': ['Бегали в библиотеку и обратно.',\n",
       "  'Пили, картёжничали, дрались и снимали девок.',\n",
       "  'Выгуливали собак.',\n",
       "  'Учились.',\n",
       "  'Развлекались игрой в карты, пьянкой, драками, снимали они тут и девок.'],\n",
       " 'labels': [0, 1, 0, 0, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train dataset\n",
    "\n",
    "ds = []\n",
    "with open('data/train.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        ds.append(json.loads(line))\n",
    "\n",
    "# реформатирование датасета чтобы было удобнее работать\n",
    "def format_dataset(example):\n",
    "    context = example['passage']['text']\n",
    "    context = re.sub(r'\\(\\d+\\)', '', context) # remove (1), (2), etc.\n",
    "    questions = [q['question'] for q in example['passage']['questions']]\n",
    "    answers = []\n",
    "    labels = []\n",
    "    for q in example['passage']['questions']:\n",
    "        answers.append([])\n",
    "        labels.append([])\n",
    "        for a in q['answers']:\n",
    "            answers[-1].append(a['text'])\n",
    "            labels[-1].append(a['label'])\n",
    "    assert len(questions) == len(answers)\n",
    "    list_of_data = []\n",
    "    for i in range(len(questions)):\n",
    "        if len(labels[i]) <= 6:\n",
    "            list_of_data.append({\n",
    "                'context': context,\n",
    "                'question': questions[i], \n",
    "                'answers': answers[i], \n",
    "                'labels': labels[i]\n",
    "            })\n",
    "    return list_of_data\n",
    "\n",
    "new_ds = []\n",
    "for example in ds:\n",
    "    new_ds.extend(format_dataset(example))\n",
    "\n",
    "new_ds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем модель [sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) для определения сродства между предложениями. Она предназначена для работы с русским языком и показала хороший результат в моих других проектах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбираем девайс\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# загружаем модель для подсчета косинусного расстояния\n",
    "embedder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "# загружаем пайплайн для предсказания ответа на вопрос\n",
    "model_for_answering_name = \"timpal0l/mdeberta-v3-base-squad2\"\n",
    "qa_pipeline = pipeline(\"question-answering\", \n",
    "                       model=model_for_answering_name, \n",
    "                       tokenizer=model_for_answering_name,\n",
    "                       device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример работы пайплайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Контекст:  (1) Но люди не могут существовать без природы, поэтому в парке стояли железобетонные скамейки — деревянные моментально ломали. (2) В парке бегали ребятишки, водилась шпана, которая развлекалась игрой в карты, пьянкой, драками, «иногда насмерть». (3) «Имали они тут и девок...» (4) Верховодил шпаной Артемка-мыло, с вспененной белой головой. (5) Людочка сколько ни пыталась усмирить лохмотья на буйной голове Артемки, ничего у неё не получалось. (6) Его «кудри, издали напоминавшие мыльную пену, изблизя оказались что липкие рожки из вокзальной столовой — сварили их, бросили комком в пустую тарелку, так они, слипшиеся, неподъёмно и лежали. (7) Да и не ради причёски приходил парень к Людочке. (8) Как только её руки становились занятыми ножницами и расчёской, Артемка начинал хватать её за разные места. (9) Людочка сначала увёртывалась от хватких рук Артемки, а когда не помогло, стукнула его машинкой по голове и пробила до крови, пришлось лить йод на голову «ухажористого человека». (10) Артемка заулюлюкал и со свистом стал ловить воздух. (11) С тех пор «домогания свои хулиганские прекратил», более того, шпане повелел Людочку не трогать.\n",
      "Вопрос:  Где бегала шпана?\n",
      "Ответ:   В парке\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "\n",
    "c = new_ds[ind]['context']\n",
    "q = new_ds[ind]['question']\n",
    "\n",
    "ans = qa_pipeline(question=q,  context=c)\n",
    "print('Контекст: ', c)\n",
    "print('Вопрос: ', q)\n",
    "print('Ответ: ', ans['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для вычисления косинусного расстояния между векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01532322, 0.3975693 , 0.5284183 ], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "payload = {\n",
    "    \"inputs\": {\n",
    "        \"source_sentence\": ans['answer'],\n",
    "        \"sentences\": new_ds[ind]['answers']\n",
    "    }\n",
    "}\n",
    "\n",
    "def cosine_sim_local(payload : dict) -> np.ndarray:\n",
    "    source = payload[\"inputs\"][\"source_sentence\"]\n",
    "    compare_to = payload[\"inputs\"][\"sentences\"]\n",
    "    source_inp = embedder.encode(source, convert_to_tensor=True)\n",
    "    compare_inp = embedder.encode(compare_to, convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(source_inp, compare_inp)[0].cpu().numpy()\n",
    "\n",
    "\n",
    "def cosine_distance(payload : dict)-> np.ndarray:\n",
    "    return 1 - np.array(cosine_sim_local(payload))\n",
    "\n",
    "cosine_distance(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим метрики accuracy и Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct(payload : dict, labels : list) -> bool:\n",
    "    return labels[np.argmin(cosine_distance(payload))] == 1\n",
    "\n",
    "def rr(payload : dict, labels : list) -> float:\n",
    "    sorted_inds = cosine_distance(payload).argsort()\n",
    "    for i, ind in enumerate(sorted_inds):\n",
    "        if labels[ind] == 1:\n",
    "            return 1 / (i + 1)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим accuracy и MRR на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2889 [00:00<03:48, 12.59it/s]/home/langley/miniconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2889/2889 [03:09<00:00, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7691242644513673\n",
      "MRR: 0.8705434406368986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_correct = []\n",
    "res_rr = []\n",
    "\n",
    "# я понимаю, что использовать по одному на gpu не лучшая идея, но на cpu сойдет\n",
    "for example in tqdm(new_ds, total=len(new_ds)):\n",
    "    c = example['context']\n",
    "    q = example['question']\n",
    "    ans = qa_pipeline(question=q,  context=c)\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"source_sentence\": ans['answer'],\n",
    "            \"sentences\": example['answers']\n",
    "        }\n",
    "    }\n",
    "    res_correct.append(is_correct(payload, example['labels']))\n",
    "    res_rr.append(rr(payload, example['labels']))\n",
    "\n",
    "print(f\"Accuracy: {np.mean(res_correct)}\")\n",
    "print(f\"MRR: {np.mean(res_rr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним со случаем когда мы вибираем случайно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2889/2889 [00:33<00:00, 86.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4648667358947733\n",
      "MRR: 0.6862524518287758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# тут можно сделать это все аналитически (без подстановки в модель), но я этого не сделал (\n",
    "\n",
    "res_correct = []\n",
    "res_rr = []\n",
    "\n",
    "for example in tqdm(new_ds, total=len(new_ds)):\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"source_sentence\": np.random.choice(example['answers']),\n",
    "            \"sentences\": example['answers']\n",
    "        }\n",
    "    }\n",
    "    res_correct.append(is_correct(payload, example['labels']))\n",
    "    res_rr.append(rr(payload, example['labels']))\n",
    "\n",
    "print(f\"Accuracy: {np.mean(res_correct)}\")\n",
    "print(f\"MRR: {np.mean(res_rr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты сравнения моделей для поиска ответа на вопрос в контексте:\n",
    "\n",
    "| Model | Accuracy | MRR |\n",
    "| --- | --- | --- |\n",
    "| [timpal0l/mdeberta-v3-base-squad2](https://huggingface.co/timpal0l/mdeberta-v3-base-squad2) | 0.7785 | 0.8748 |\n",
    "| [AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru](https://huggingface.co/AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru) | 0.7695 | 0.8696 |\n",
    "| [squad_ru_bert](https://docs.deeppavlov.ai/en/0.9.0/features/models/squad.html) от deeppavlov | 0.7681 | 0.8687 |\n",
    "| Случайно выбираем ответ | 0.4600 | 0.6885 |\n",
    "\n",
    "Собственно оставим верхнюю модель, тк она показала лучший результат\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка запросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос + Документ\n",
    "\n",
    "Выше я разобрал случай когда подается запрос вида: Вопрос + Документ. Его можно обрабатывать вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 2'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Берлин — столица Германии, один из 16 штатов страны. Население города составляет 3,7 млн человек, что делает его самым населённым городом страны. Берлин является крупнейшим городом страны по площади (891,85 км²). Берлин расположен в восточной части страны, в 70 км от границы с Польшей. Город является одним из крупнейших транспортных узлов Европы, в нём находятся 2 аэропорта, 2 международных вокзала, 6 автовокзалов, а также крупнейший в Европе порт на реке Хафель.\"\n",
    "question = \"Сколько аэропортов в Берлине?\"\n",
    "\n",
    "ans = qa_pipeline(question=question, context=context)\n",
    "ans['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Вопрос\n",
    "\n",
    "Другой случай, когда нам необходимо отвечать на вопрос без предоставленного заранее документа, а по какой-то коллекции документов. Для этого предложим такую схему:\n",
    "\n",
    "- Индексируем документы\n",
    "- Предобрабатываем запрос\n",
    "- Ищем подходящие документы по максимальному cosine similarity\n",
    "- Конкатенируем найденные документы в один большой документ\n",
    "- Ищем ответ в этом большом документе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо найти модель которая будет хорошо работать на этапе поиска подходящих документов. Для этого я сделал следующий эксперимент:\n",
    "\n",
    "- Взял все 500 документов из датасета\n",
    "- Взял 500 случайных вопросов из датасета. Один вопрос - на один документ\n",
    "- Предобработал документы и вопросы\n",
    "- Посчитал косинусное сродство между вопросом и документом\n",
    "- Посмотрел в насколько хорошо модель находит подходящий документ в топе из K документов (accuracy@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сэмплирование документов\n",
    "embedder = SentenceTransformer('cointegrated/rubert-tiny2')\n",
    "\n",
    "corpus = [example['passage']['text'] for example in ds]\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# сэмплирование запросов\n",
    "queries = [example['passage']['questions'][0]['question'] for example in ds]\n",
    "query_embeddings = embedder.encode(queries, convert_to_tensor=True)\n",
    "\n",
    "# подсчет косинусного расстояния\n",
    "cos_scores = util.cos_sim(query_embeddings, corpus_embeddings).cpu().numpy()\n",
    "assert cos_scores.shape[0] == cos_scores.shape[1]\n",
    "\n",
    "y_true = np.arange(len(queries))\n",
    "\n",
    "# подсчет метрики\n",
    "top_k_accuracy_score(y_true, cos_scores, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:\n",
    "\n",
    "model | Accuracy@1 | Accuracy@5 | Accuracy@10 |\n",
    "| --- | --- | --- | --- |\n",
    "| [rubert-tiny2](https://huggingface.co/cointegrated/rubert-tiny2) | 0.494 | 0.712 | 0.77 | \n",
    "[paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) | 0.528 | 0.684 | 0.758 |\n",
    "\n",
    "Будем юзать [rubert-tiny2](https://huggingface.co/cointegrated/rubert-tiny2) и возвращать 5 самых подходящих документов. Больше нет смысла тк максимально поддерживаемое количество токенов у этой модели 2048, что примерно 5-7 документов в зависимости от длины документа (средняя длина документа ~320 токенов).\n",
    "\n",
    "Писать функции для индексирование не нужно, я использовал библиотеку [langchain](https://www.langchain.com/). С помощью [Annoy](https://python.langchain.com/docs/integrations/vectorstores/annoy) я индексировал документы и находил в полученной базе данных подходящие для ответа на вопрос документы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cointegrated/rubert-tiny2\"\n",
    "model_kwargs = {'device': 'cuda:0'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings_function = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "\n",
    "db = Annoy.from_texts(corpus, embeddings_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Контекст:  (1) Стояло жаркое лето, столько работы вокруг! (2) Белочка трудилась с утра и до вечера, не покладая рук. (3) Ей даже перекусить было некогда, только и делала, что таскала шишки в свое дупло. (4) Но места в дупле оставалось не так уж и много, ведь всё дупло было завалено припасами с прошлых лет. (5) Когда шишки совсем перестали помещаться в дупло, белочка загрустила: что же теперь делать? (6) Куда складывать питание? (7) Пошла белочка к дятлу и стала просить его расширить ей дупло. (8) - Ну, пожалуйста, дорогой дятлик, выдолби мне дупло побольше, а то маленькое оно у меня, ничего в нем не помещается! (9) Дятел был добрым, потому и согласился. (10) Залез он к белке в дупло, смотрит, а дупло-то у нее огромное! (11) И еды в нем видимо-невидимо. (12) Хватит, чтобы весь лес прокормить на несколько лет вперед! (13) Выдолбил дятел белочке дупло и говорит: - Что ж ты гонишь от себя зверушек голодных? (14) Еды-то у тебя на всех хватит! (15) Ты бы не жадничала, белочка, гляди, все тебе аукнется! (16) - А ты лети вон отсюда, птица настырная! (17) Не твоего ума дела! (18) – закричала белочка. (1) Жил в горах провинции Канвон старый тигр. (2) Повстречал он однажды зайца и говорит: – Голоден я и сейчас тебя съем! (3) А заяц – уж очень был хитер – отвечает: – Дорогой дядюшка! (4) Не пойдешь ли со мной? (5) Я принёс всякой вкусной еды! (6) Пошел тигр следом за зайцем. (7) Спустились они в долину. (8) Вытащил заяц одиннадцать круглых камешков, улыбнулся и говорит: – Ел ты когда-нибудь такую вкуснятину? (9) Поглядел тигр, любопытно ему и спрашивает: – А как их есть? (10) Отвечает заяц: – Уж чего проще! (11) Брось их в огонь, а как покраснеют, вытаскивай да ешь. (12) Жареные они вкуснее! (13) Развел заяц огонь, камешки в него бросил. (14) Смотрит тигр, как жарятся камни, слюнки глотает. (15) А заяц ему говорит: – Дорогой дядюшка! (16) Сбегаю-ка я, соусу тебе принесу своего! (17) Чтобы вкуснее было. (18) Только смотри один не ешь, меня подожди! (19) Там всего десять штук, это нам на двоих! (1) На следующее утро белочка проснулась от какого-то тихого попискивания. (2) Внизу, под деревом она увидела маленького мышонка, который суетился и складывал у дерева какие-то прутики. (3) Белочка спустилась к нему и спросила, что это он делает. (4) - Как это, что делаю? – удивился мышонок, - тебе помогаю! (5) Твоё новое дупло нужно будет утеплить, ведь зима скоро! (6) Вот я прутики и таскаю! (7) Тут белочка вспомнила, что прошлой зимой этот мышонок приходил к ней просить семечек, а она его прогнала. (8) - Что же ты помогаешь мне, ведь я тебе не помогла в трудную минуту? (9) - Да потому и помогаю, что знаю, как это тяжело, когда беда пришла, а помочь некому, - ответил мышонок. (10) Тут прилетел дятел, улыбнулся белочке и сказал: - Бог с тобой, поговорили мы тут со зверями лесными, не сердимся мы на тебя больше. (11) Но и ты запомни этот урок, - сказал он и выдолбил белочке небольшое, но уютное дупло. (1) Однажды тигр, встретив зебру, завёл с ней разговор: — Скажи зебра, почему ты ходишь по равнине спокойно и не боишься меня? (2) — Я вижу тебя издалека, и знаю, что легко могу спрятаться от тебя за ветками, прыгнув в кусты. (3) Ведь я не просто так хожу вся в полосках. (4) Они помогают мне исчезнуть среди ветвей всякий раз, как только кто-нибудь собирается поохотиться за мной, — настороженно ответила она. (5) — Ах, зебра, твои полоски такие красивые. (6) Не могла бы ты поделится со мной, у тебя ведь их много! – продолжал разговор тигр. (7) - Я знаю, что ты хитёр, но я не такая глупая, как ты думаешь. (8) Как только я подарю тебе свои полосы, врагов у меня станет ещё больше. (9) И я не смогу больше прятаться за ветками, потому что там будешь ты. (10) Но тигр был не только хитёр, он был ещё и мудрым. (11) Немного подумав, он предложил: — Давай заключим с тобой договор. (12) Ты даёшь мне немного полосок, а я уйду охотиться в далёкие края, где мы с тобой никогда не встретимся. (13) И врагов станет у тебя на одного меньше. (14) Чуть поразмыслив, зебра скинула с себя часть полосок на землю и исчезла за ветками кустов. (15) С тех пор никто больше не видел ярко-рыжего тигра в краях. (16) Он сдержал слово и ушёл в самые дальние и дремучие леса. (17) Там он стал настоящим королём своих владений, благодаря своей необыкновенной новой и красивой шкуре. (1) Но люди не могут существовать без природы, поэтому в парке стояли железобетонные скамейки — деревянные моментально ломали. (2) В парке бегали ребятишки, водилась шпана, которая развлекалась игрой в карты, пьянкой, драками, «иногда насмерть». (3) «Имали они тут и девок...» (4) Верховодил шпаной Артемка-мыло, с вспененной белой головой. (5) Людочка сколько ни пыталась усмирить лохмотья на буйной голове Артемки, ничего у неё не получалось. (6) Его «кудри, издали напоминавшие мыльную пену, изблизя оказались что липкие рожки из вокзальной столовой — сварили их, бросили комком в пустую тарелку, так они, слипшиеся, неподъёмно и лежали. (7) Да и не ради причёски приходил парень к Людочке. (8) Как только её руки становились занятыми ножницами и расчёской, Артемка начинал хватать её за разные места. (9) Людочка сначала увёртывалась от хватких рук Артемки, а когда не помогло, стукнула его машинкой по голове и пробила до крови, пришлось лить йод на голову «ухажористого человека». (10) Артемка заулюлюкал и со свистом стал ловить воздух. (11) С тех пор «домогания свои хулиганские прекратил», более того, шпане повелел Людочку не трогать.\n",
      "Вопрос:  Где бегала шпана?\n",
      "Ответ:   В парке\n"
     ]
    }
   ],
   "source": [
    "q = \"Где бегала шпана?\"\n",
    "\n",
    "docs = db.similarity_search(q, k=5)\n",
    "c = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "ans = qa_pipeline(question=q,  context=c)\n",
    "print('Контекст: ', c)\n",
    "print('Вопрос: ', q)\n",
    "print('Ответ: ', ans['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving database to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local('train_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Annoy.load_local('train_db', embeddings_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация в streamlit приложении\n",
    "\n",
    "# Выводы\n",
    "\n",
    "- Наиболее подходящей моделью для поиска ответа на вопрос в контексте оказалась [timpal0l/mdeberta-v3-base-squad2](https://huggingface.co/timpal0l/mdeberta-v3-base-squad2). Она показала accuracy 0.7785 и MRR 0.8748. Это лучший результат среди всех моделей, которые я пробовал.\n",
    "\n",
    "- Для поиска подходящих документов я использовал модель [rubert-tiny2](https://huggingface.co/cointegrated/rubert-tiny2). Она показала accuracy@5 0.712. То есть в 71% случаев подходящий документ находится в топе из 5 документов.\n",
    "\n",
    "- Для правильно вытащенного документа с вероятностью 78% модель находит правильный ответ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
